{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "train_slip_detection_network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.9 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![logo](https://neutouch.eu/templates/yootheme/cache/g37-01577415.png)\n",
        "# NeuTouch summer school on Touch and Robotics\n",
        "Tutorial: Slip Detection with Neural Networks\n",
        "\n",
        "In this tutorial we will look into incipient slip detection and slip classification with deep neural networks. We will experiment with and evaluate various neural network architectures to detect and classify slippage.\n",
        "To this end, we will work on a pre-recorded data set from our 16x16 tactile sensor array, comprising tactile time series data for three different situations:\n",
        "- stable grasp condition\n",
        "- translational slip\n",
        "- rotational slip\n"
      ],
      "metadata": {
        "id": "nAfMgIcOkP7C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Let's download the data set first:\n",
        "!wget \"https://uni-bielefeld.sciebo.de/s/7vi5lX9WO1VmvIZ/download\" -O \"data_stable_slip_rotate.pkl\""
      ],
      "outputs": [],
      "metadata": {
        "id": "o026L5tpXCTr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94be0e6e-8b2c-4fe2-ee1b-3408565607bc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Actually load the data\n",
        "import pickle\n",
        "\n",
        "data = pickle.load(open(\"data_stable_slip_rotate.pkl\", \"rb\"), encoding='latin1')"
      ],
      "outputs": [],
      "metadata": {
        "id": "ESKLclFdS2Lk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task: Visually inspect the data\n",
        "\n",
        "Use [matplotlib's animation](https://matplotlib.org/stable/api/animation_api.html) to create videos for all three classes (stable, translation, rotation)\n",
        "and [embed them into the notebook](http://louistiao.me/posts/notebooks/embedding-matplotlib-animations-in-jupyter-as-interactive-javascript-widgets/)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# The data is organized into three classes:\n",
        "fig = plt.figure()  # create a new figure\n",
        "for idx, key in enumerate(data.keys()):\n",
        "    ax = fig.add_subplot(1, 3, idx+1, xticks=[], yticks=[],  # add subplot w/o any axis ticks\n",
        "                         xlabel=\"{name}: {shape}\".format(name=key, shape=data[key].shape))\n",
        "    ax.imshow(data[key][np.random.randint(0, len(data[key]))], cmap = \"Greys\")  # plot a random sample"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Z40x5j30ZIOD",
        "outputId": "ac316c7f-7761-45ba-fd4c-b263347df1e7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline CNN classification of raw data\n",
        "\n",
        "As a baseline approach, we illustrate here how to use a CNN to classify the raw data.\n",
        "As seen above, each class comprises 50k frames of consecutive sensor recordings, recorded at a frame rate of 1kHz. Hence, we have 50s of data for each class.\n",
        "Obviously, the network cannot predict from a single sample whether there is slippage or not. So, let's chop the whole time-series into short sequences of fixed length, say 32 samples, which then can be fed into a neural network."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Import Keras + TensorFlow packages\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as keras\n",
        "\n",
        "# Define a random seed to have deterministic results\n",
        "np.random.seed(11)"
      ],
      "outputs": [],
      "metadata": {
        "id": "HGOFo_hnWU66"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Prepare the dataset for training: chop into sequences of given length and assign numeric class labels\n",
        "def prepare_dataset(length=32, stride=8):\n",
        "   # map textual labels onto numeric class labels\n",
        "   label_mapping = dict(stable=0, translation=1, rotation=2)\n",
        "   xs = []\n",
        "   ys = []\n",
        "   for key in data.keys():\n",
        "      N = len(data[key])\n",
        "      labels = np.full(N, label_mapping[key]) # generate array with identical numeric labels for key\n",
        "      # https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/TimeseriesGenerator\n",
        "      x, y = keras.preprocessing.sequence.TimeseriesGenerator(data[key], labels, length=length, stride=stride, batch_size=N)[0]\n",
        "      print(key, x.shape, y.shape)\n",
        "      xs.append(x)\n",
        "      ys.append(y)\n",
        "\n",
        "   # combine data of all classes into a single data set\n",
        "   X = np.concatenate(xs) / 4096  # normalize 12bit ADC data (0..2^12) into range (0..1)\n",
        "   Y = np.concatenate(ys)\n",
        "   print(\"combined\", X.shape, Y.shape)\n",
        "\n",
        "   # optionally perform FFT on input data X\n",
        "   # https://numpy.org/doc/stable/reference/generated/numpy.fft.rfft.html\n",
        "   return X, Y\n",
        "\n",
        "X, Y = prepare_dataset()\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def unison_shuffle_arrays(x, y):\n",
        "\tassert len(x) == len(y)\n",
        "\tp = np.random.permutation(len(x))\n",
        "\treturn x[p], y[p]  # return new permutation of x and y"
      ],
      "outputs": [],
      "metadata": {
        "id": "WjX4PhEXYx7T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def train_test_split(X, Y, ratio=0.8):\n",
        "   split=int(len(X)*ratio)\n",
        "   X_train = X[:split]\n",
        "   Y_train = Y[:split]\n",
        "\n",
        "   X_test = X[split:]\n",
        "   Y_test = Y[split:]\n",
        "\n",
        "   return X_train, X_test, Y_train, Y_test"
      ],
      "outputs": [],
      "metadata": {
        "id": "nHtfoUKxZAcY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Simple MLP with a single hidden layer\n",
        "def simple_mlp(input_shape, num_classes=3):\n",
        "  model = keras.models.Sequential(name=\"SimpleMLP\")\n",
        "  model.add(keras.layers.Flatten(input_shape=input_shape))  # Flatten input tensor into single vector\n",
        "  model.add(keras.layers.Dense(64, activation='relu'))  # hidden layer with 64 neurons\n",
        "  model.add(keras.layers.Dense(num_classes))  # dense classification layer\n",
        "  return model\n",
        "\n",
        "# Basic network with a single CNN layer\n",
        "def simple_cnn(input_shape, num_classes=3):\n",
        "  model = keras.models.Sequential(name=\"SimpleCNN\")\n",
        "  model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "  model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(keras.layers.Flatten())  # Flatten tensor into single vector\n",
        "  model.add(keras.layers.Dense(num_classes))  # dense classification layer\n",
        "  return model\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "v6jbsjEMZEop"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf logs/"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(*unison_shuffle_arrays(X, Y), ratio=0.8)\n",
        "\n",
        "def train(model):\n",
        "   model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                 optimizer=keras.optimizers.RMSprop(),\n",
        "                 metrics=['sparse_categorical_accuracy'])\n",
        "   model.summary()\n",
        " \n",
        "   # Specify log directory for TensorBoard\n",
        "   log_dir = \"logs/\" + model.name\n",
        " \n",
        "   # Initialize TensorBoard\n",
        "   tb = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        " \n",
        "   # Fit data to the model!\n",
        "   model.fit(X_train, Y_train,\n",
        "             batch_size=16, epochs=10,\n",
        "             validation_data=(X_test, Y_test),\n",
        "             callbacks=[tb])\n",
        " \n",
        "   score = model.evaluate(X_test, Y_test, verbose=False)\n",
        "   print('Test loss:', score[0])\n",
        "   print('Test accuracy:', score[1])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train(simple_mlp(X_train.shape[1:]))\n",
        "train(simple_cnn(X_train.shape[1:]))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Inspect results with TensorBoard\n",
        "%tensorboard --logdir logs"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task: Experiment!\n",
        "Try various networks:\n",
        "- Add more CNN layers\n",
        "- Adapt size of layers, size of kernels, num of kernels\n",
        "- Experiment with different optimizers: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
        "- Compare raw inputs vs. FFT preprocessing. Are frequencies and/or phases important?\n",
        "\n",
        "Improve generalization\n",
        "- Introduce drop-out: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout\n",
        "- Use batch normalization: https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization\n",
        "- Augment your data: https://www.tensorflow.org/tutorials/images/data_augmentation\n",
        "  Which data augmentation strategies are meaningful for this type of data?"
      ],
      "metadata": {}
    }
  ]
}